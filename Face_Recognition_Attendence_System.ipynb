{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cddb5521-6016-42d1-8cb4-df7155ee21e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face_recognition in c:\\users\\user\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from face_recognition) (8.1.7)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from face_recognition) (19.24.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from face_recognition) (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\anaconda3\\lib\\site-packages (from face_recognition) (10.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22fecec4-b1f0-4adb-9658-1e98687f9d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fe66ca-8ee8-4fd2-904c-a988d39e9a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition #Recognize faces and compare it with the faces already in the database\n",
    "import cv2 #get input from webcam(opencv) and process it and give it to the face_recognition\n",
    "import numpy as np\n",
    "import csv #Handle the csv file \n",
    "import os # package to access the files(if have 100 of photos you can automate by using os)\n",
    "import glob\n",
    "from datetime import datetime #Get exact date and time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387f2e04-c7de-4bdb-a5f5-f2837fdfd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f824e187-1624-4408-9e22-b15b35c16eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and get face encodings\n",
    "Bill_image = face_recognition.load_image_file(\"photos/Bill.jpg\")\n",
    "Bill_encoding = face_recognition.face_encodings(Bill_image)[0]\n",
    "\n",
    "Elon_image = face_recognition.load_image_file(\"photos/Elon.jpg\")\n",
    "Elon_encoding = face_recognition.face_encodings(Elon_image)[0]\n",
    "\n",
    "Mark_image = face_recognition.load_image_file(\"photos/Mark.jpg\")\n",
    "Mark_encoding = face_recognition.face_encodings(Mark_image)[0]\n",
    "\n",
    "Steve_image = face_recognition.load_image_file(\"photos/Steve.jpg\")\n",
    "Steve_encoding = face_recognition.face_encodings(Steve_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c7a5c45-c50e-4507-b68f-efd4031cb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_encoding = [\n",
    "    Bill_encoding,  # Corresponds to \"Bill\"\n",
    "    Elon_encoding,  # Corresponds to \"Elon\"\n",
    "    Mark_encoding,  # Corresponds to \"Mark\"\n",
    "    Steve_encoding  # Corresponds to \"Steve\"\n",
    "]\n",
    "\n",
    "known_faces_names = [\n",
    "    \"Bill\",  # Matches the first encoding\n",
    "    \"Elon\",  # Matches the second encoding\n",
    "    \"Mark\",  # Matches the third encoding\n",
    "    \"Steve\"  # Matches the fourth encoding\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c04b20-20f5-468d-9cef-2b045749d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "students = known_faces_names.copy()\n",
    "\n",
    "# Initialize variables\n",
    "face_locations = []# to save face locations\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "s = True\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "# Format the current date to \"YYYY-MM-DD\"\n",
    "current_date = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "f = open(current_date + '.csv', 'w+', newline='')# Open or create a file with the current date as the filename\n",
    "lnwriter = csv.writer(f) # Initialize CSV writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a110c2-14d5-44ef-8445-19dc43f00c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attendance marked for: Elon\n",
      "Remaining students: ['Bill', 'Mark', 'Steve']\n",
      "Attendance marked for: Mark\n",
      "Remaining students: ['Bill', 'Steve']\n",
      "Attendance marked for: Bill\n",
      "Remaining students: ['Steve']\n",
      "Attendance marked for: Steve\n",
      "Remaining students: []\n",
      "All students marked present! Closing camera...\n",
      "Closing after attendance marking...\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = video_capture.read()  # ERROR 1: Fixed syntax error\n",
    "    \n",
    "    # Check if frame was captured successfully\n",
    "    if not ret:  # ERROR 2: Added frame validation\n",
    "        print(\"Failed to capture frame from camera\")\n",
    "        break\n",
    "    \n",
    "    # Resize frame for faster processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    # Convert BGR to RGB and ensure proper data type\n",
    "    rgb_small_frame = np.ascontiguousarray(small_frame[:, :, ::-1].astype(np.uint8))\n",
    "    \n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "    \n",
    "    face_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_face_encoding, face_encoding)\n",
    "        face_distance = face_recognition.face_distance(known_face_encoding, face_encoding)\n",
    "        best_match_index = np.argmin(face_distance)\n",
    "        \n",
    "        if matches[best_match_index]:\n",
    "            name = known_faces_names[best_match_index]\n",
    "        else:\n",
    "            name = \"Unknown\"  # ERROR 3: Handle case when no match is found\n",
    "            \n",
    "        face_names.append(name)\n",
    "        \n",
    "        # ERROR 4: Moved attendance logic inside the face detection loop and added proper conditions\n",
    "        if name in students and name != \"Unknown\":  # Check if the student is in the students list\n",
    "            students.remove(name)  # Remove the student after marking them present\n",
    "            print(f\"Attendance marked for: {name}\")\n",
    "            print(f\"Remaining students: {students}\")\n",
    "            # Record attendance\n",
    "            current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            lnwriter.writerow([name, current_time])\n",
    "            f.flush()  # ERROR 5: Added flush to ensure data is written immediately\n",
    "            \n",
    "            # Check if all students are marked present\n",
    "            if len(students) == 0:\n",
    "                print(\"All students marked present! Closing camera...\")\n",
    "                break\n",
    "    \n",
    "    # ERROR 6: Added face rectangle drawing for better visualization\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "        \n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "    \n",
    "    # Display video feed\n",
    "    cv2.imshow(\"attendance system\", frame)\n",
    "    \n",
    "    # Break loop on key press\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    elif key == ord('c'):\n",
    "        print(\"Closing after attendance marking...\")\n",
    "        break\n",
    "\n",
    "# Release video capture and close all windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12efc4c-f9ba-4057-8aef-8931471765b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
